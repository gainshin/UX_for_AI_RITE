# 摘要：人機協作（Human-in-the-loop）功能，維持使用者監督與自主權。包括行動計畫、分支、引文、控制項、成本估算、草稿模式、記憶、參考資料、樣本回應、共享視窗、思維流、多樣化和驗證等

## Action plan

### 頁面整體介紹

「Action plan（行動計畫）」是 AI 在執行複雜或高耗能任務前，先展示其計畫步驟，讓使用者有機會確認或調整。這能確保執行過程的透明度與可預測性，避免錯誤或浪費算力。行動計畫可以是建議性質（僅供參考）或合約性質（需使用者驗證後才能繼續）。其主要權衡在於執行速度與安全性之間。

### 變體與形式

- **`Step lists`（步驟清單）**：線性的行動大綱，通常在執行前需要快速確認。
- **`Execution previews`（執行預覽）**：與程式碼或自動化相關的結構化計畫，設有明確的批准關卡。
- **`Content outlines`（內容大綱）**：文件或簡報的草稿架構，不一定需要確認。
- **`Adaptive plans`（適應性計畫）**：在執行過程中會演變的計畫，有時需要反覆確認。

### 設計建議

- **先展示計畫再投入資源**：預覽讓使用者確信系統方向正確，避免浪費算力。
- **保持計畫易於瀏覽**：使用者應在幾秒內理解意圖，避免過於技術性或冗長的計畫。
- **讓計畫可修改**：若使用者發現錯誤，應提供工具讓他們當場修正。
- **允許使用者收合或跳過**：對於已信任系統的資深使用者，提供隱藏或最小化計畫的捷徑。
- **確保計畫與執行一致**：系統必須遵循計畫，若有偏差需更新或解釋，否則會侵蝕信任。

### 相關模式（Related Patterns）

- **`Stream of Thought`**：執行期間展示 AI 的思維過程與工具使用，反映最初的計畫。
- **`Verification`**：當行動涉及覆蓋工作、大量算力或洩漏個資時，需要使用者驗證才能繼續。
- **`Draft mode`**：對於非逐步生成但仍需大量算力的任務，使用草稿模式讓使用者在最終版本產出前進行調整。

### 案例示例（Pattern Examples）

- **`Chronicle`**：展示每張投影片的內容大綱及佈局格式細節供使用者審查。
- **`Cursor`**：在設定中將「行動計畫」功能設為可選。
- **`Gamma`**：產生簡報大綱視圖，並要求使用者確認後繼續。
- **`Github Copilot`**：建立高層次計畫供使用者修改，並詳列要新增、變更或移除的檔案清單以供額外驗證。
- **`Jasper`**：在產出最終版本前，先撰寫長文草稿供使用者審查。
- **`Replit`**：產生完整的行動計畫預覽供使用者確認。
- **`Zapier`**：在 AI 草稿模式下，建立其計畫工作流程的大綱供使用者調整。

## Branches

### 頁面整體介紹

「Branches（分支）」允許使用者在不失去原始路徑的情況下，建立多個生成或探索的路徑。這有助於使用者在不確定最終目標時，嘗試不同的提示、參數或模型，並保留每次探索的紀錄。

### 分支類型

- **`Text chat branches`（文字聊天分支）**：將對話分成平行的線程，保留分支點前的對話與上下文。
- **`Variant branches`（變體分支）**：基於原始來源自動生成多個路徑，以供獨立比較或編輯。
- **`Workflow branches`（工作流程分支）**：在圖形化節點處分支，讓不同的參數集或工具並行運作。

### 設計建議

- **維持與來源的關係**：提供返回原始提示的連結或參考，讓使用者可以追溯源頭。
- **將分支設為明確操作**：在訊息操作、成品預覽或工作流程節點上加入清晰的「分支」控制項。
- **讓每個分支獨立發展**：建立分支時，顯示繼承的上下文摘要，並允許使用者取消選擇不相關的上下文。
- **定義輕量的合併模式**：例如，允許「將此答案採納至主線程」並附註，或將選定的變體提升為新基準。

### 相關模式（Related Patterns）

- **`Cost estimates`**：分支會快速增加算力成本，需確保使用者不會因多次操作而無意中超支。
- **`Chained action`**：鏈式行動可包含多個分支，對單一提示進行不同方向的迭代。
- **`Variations`**：分支提供了一種有意生成單一結果變體的方式，特別是在發散性情境中（如圖像或影片生成）。

### 案例示例（Pattern Examples）

- **`Firefly`**：支援有限的分支選項，允許從單一變體分支成額外提示，同時保留與原始版本的關係。
- **`Character.ai`**：即使透過分支開始新聊天，仍保留原始對話的上下文。
- **`OpenAI`**：支援分支對話，分支點前的上下文會被保留並複製到新線程中。
- **`Flora`**：在畫布上視覺化展示分支，使用者可透過鏈式行動嘗試不同模型、提示組合等。
- **`Midjourney`**：每次執行提示都會創造可獨立發展的變體分支，並提供返回原始版本的連結。
- **`Rivet`**：支援聚合性而非發散性的分支，用於不同條件或狀態下的不同提示與行動。
- **`Typing mind`**：使用「fork」一詞來建立一個包含該點之前所有上下文的新對話。

## Citations

### 頁面整體介紹

「Citations（引文）」讓使用者能看到 AI 回應的來源，將生成內容與其基礎材料（如 PDF、網頁或內部資料庫）連結起來，以提高透明度並協助使用者驗證資訊。引文也可能影響使用者對 AI 權威性的看法，但若摘要出現幻覺或錯誤陳述，則會產生反效果。

### 變體與形式

- **`Inline highlights`（行內醒目提示）**：最適合附加材料，如 PDF。
- **`Direct quotations`（直接引用）**：適用於較長文本或逐字稿，顯示模型賴以生成摘要的具體引文。
- **`Multi-source references`（多來源參考）**：常見於搜尋與資訊匯總。
- **`Lightweight links`（輕量連結）**：主要用於驗證而非探索，例如在文末列出完整 URL。

### 設計建議

- **依據上下文決定具體程度**：呈現事實性資訊時，應指向確切段落或時間戳；若使用者意圖是廣泛探索，則提供更廣泛的參考資料集。
- **將引文放在使用者預期的位置**：行內提示適用於句子層級的聲明，側邊欄或抽屜則更適合長文探索。
- **尊重使用者的專注力**：允許使用者懸停預覽或點擊查看完整來源，平衡速度與徹底性。
- **明確標示失效或遺失的引文**：若來源無法使用，直接標示出來，而不是隱藏。
- **使用元資料輔助掃描**：標題、網站名稱和圖示有助於快速判斷相關性。
- **允許使用者重新界定參考範圍**：提供篩選、移除或附加新檔案的控制項，無需重啟整個流程。

### 相關模式（Related Patterns）

- **`Summary`**：搭配摘要使用，引導使用者探索原始材料。
- **`Synthesis`**：從多個來源合成的資訊可能使用多個引文。
- **`Footprints`**：作為返回原始材料的足跡，為匯總摘要提供來源證明。

### 案例示例（Pattern Examples）

- **`Adobe Acrobat`**：在摘要面板中直接引用 PDF 內的段落，方便跳轉至來源文本。
- **`Copy.ai`**：在摘要附近顯示相關參考資料及引文。
- **`Dovetail`**：協助使用者將 UX 研究的洞見追溯回原始來源，如使用者訪談。
- **`Intercom Fin Copilot`**：提供引文，幫助客戶理解 AI 回應的來源。
- **`Google`**：摘要位於搜尋結果上方，並附有特色參考資料的引文。
- **`Granola`**：自動摘要提供引文，轉述或直接引用逐字稿片段。
- **`Notion`**：使用引文讓使用者找到深藏在公司文件中的資訊。
- **`Perplexity`**：在搜尋中使用引文，將結果呈現為資訊的綜合而非排序列表。
- **`Sana`**：在彈出視窗中顯示引文，並醒目提示來源材料的相關部分。

## Controls

### 頁面整體介紹

「Controls（控制項）」讓使用者能夠停止、暫停和管理 AI 的行動，避免浪費時間和金錢等待不理想的提示結果。這讓使用者始終處於主導地位。

### 常見控制項

- **`Stop button`（停止按鈕）**：最常見的控制項，允許使用者在生成中途暫停請求，但會導致進度遺失。
- **`Pause button`（暫停按鈕）**：允許在不遺失進度的情況下停止工作，常見於耗時較長的 AI 任務。
- **`Fast-forward`（快進）**：對於較長的回應或工作流程，AI 可能會引入此選項以確認使用者希望繼續。
- **`Play`（播放）**：用於啟動新任務，常見圖示為播放鍵或紙飛機。

### 設計建議

- **立即停止**：停止按鈕應立即中止所有後端處理，釋放資源。
- **保持上下文**：即使生成被停止，也應保留使用者的原始提示和所有上下文。
- **提供重新生成選項**：在停止後，應提供清晰的「重新生成」或「編輯提示」選項。
- **明確傳達狀態**：在 AI 處理期間，應有視覺提示（如動畫或文字）告知使用者系統正在運作。
- **允許即時調整**：允許使用者在生成過程中引入新上下文或調整方向，而無需完全停止。
- **展示樣本回應**：若提示將生成多個結果，先展示樣本回應以供確認。

### 相關模式（Related Patterns）

- **`Action plan`**：在執行前展示計畫，讓使用者能及早發現問題並停止。
- **`Stream of Thought`**：執行時顯示 AI 的思緒，讓使用者判斷是否需要介入。
- **`Sample response`**：在繼續生成前展示樣本回應，作為一種內建的控制點。

### 案例示例（Pattern Examples）

- **`Bolt`**：允許在生成中途停止。
- **`ChatGPT`**：允許使用者跳過研究任務，直接開始生成回應。
- **`Claude`**：在生成提示時，將操作按鈕轉換為停止按鈕。
- **`Figma`**：在側邊欄展示標準的停止按鈕。
- **`Julius`**：允許使用者從工作流程的任一步驟開始執行。
- **`Notion`**：使用 `esc` 鍵停止生成。
- **`Perplexity`**：在研究模式下，允許使用者在生成過程中引入新上下文。
- **`Replit`**：支援佇列功能，讓使用者將新提示加入待辦清單。

## Cost estimates

### 頁面整體介紹

「Cost estimates（成本估算）」能幫助使用者在執行任何操作前，了解不同提示、參數和模型組合的相對成本，將 AI 成本透明化。估算的成本通常顯示在關鍵操作旁邊，讓使用者可以即時看到調整選項對「花費」的影響。

### 影響成本的常見選項

- **模型大小與家族**：較大的模型每個 token 消耗更多算力。
- **提示長度與上下文視窗**：較長的提示或複雜的行動需要更多 AI 的「思考能力」。
- **預期輸出長度**：詳盡的回應會使用更多輸出 token。
- **鏈式或代理計畫中的步驟數量**：工作流程和鏈式行動會快速累積成本。
- **推論步驟或迴圈次數**：模型用來精煉思考的每個計算週期都會增加總成本。

### 設計建議

- **明確單位**：清楚告知使用者估算的單位，例如「約 3,200 輸入 token」或「12 點數可生成 1 秒 Gen-4 影片」。
- **以使用者理解的單位為基準**：將 token、字元、秒數等單位盡可能對應回金錢，並解釋換算規則。
- **對未知數顯示範圍**：由於無法預知輸出 token 數，可以根據最大 token 數或典型長度呈現一個範圍。
- **突顯成本驅動因素**：將估算分解為系統提示、檢索上下文、使用者輸入等部分，標示出成本較高的部分。
- **提供更便宜的選項**：如果任務不緊急，可以建議批次模式並顯示更新後的估算成本與時間。
- **獎勵新手引導**：確保使用者在引導流程中有足夠的 token 來充分了解產品。
- **將估算放在決策點**：將成本估算放在提示框旁、步驟產生器中或基於點數的工具的操作按鈕上。

### 相關模式（Related Patterns）

- **`Chained action`**：在步驟和流程層級顯示預估的執行成本，避免耗盡使用者的點數。
- **`Draft mode`**：支援草稿模式，避免使用者使用過於強大的模型來完成任務，浪費點數。
- **`Model management`**：在模型選擇器中顯示使用不同模型的相對成本。

### 案例示例（Pattern Examples）

- **`Adobe Firefly`**：在操作按鈕附近列出生成成本。
- **`Console`**：在提示範例庫中以貨幣而非點數顯示執行預設提示的成本。
- **`ElevenLabs`**：在輸入框中明確列出生成的總成本。
- **`FloraFauna.ai`**：在單一節點的模型選擇器中列出 token 估算。
- **`Gemini`**：在其遊樂場中顯示提示的預估成本。
- **`Krea`**：在產生器側邊欄底部包含點數成本估算。
- **`Udio`**：在建立面板頂部顯示 token 估算，並在使用者設定輸入時即時更新。
- **`v0`**：當附加功能被納入建構提示時，顯示其成本。
- **`Kling.ai`**：在生成按鈕旁的彈出視窗中顯示生成成本。

## Draft mode

### 頁面整體介紹

「Draft mode（草稿模式）」讓使用者在投入完整的、資源密集型的執行前，能以較少的細節或較弱的處理能力開始工作。這種功能支援一種高效的迭代過程，早期生成速度更快，使用者花費較少的算力或點數就能得到預覽，並在準備好後輕鬆切換到更高品質的模型。

### 顯式與隱式草稿

- **顯式草稿**：在視覺媒體中，明確標示草稿模式有助於管理使用者期望，並將其定位為節省時間和金錢的正面工具。
- **隱式草稿**：允許使用者減少生成步驟數，這會降低 AI 推理的逼真度，同時消耗較少的算力。這是一個技術概念，通常隱藏在設定中供高階使用者探索。

### 設計建議

- **明確標示草稿**：使用者不應對系統產出低保真版本感到驚訝。無論是音訊片段、文件大綱還是低品質圖片，都要確保使用者保有控制感和理解力。
- **明確說明權衡**：描述草稿模式中減少了什麼，例如模型等級、步驟、解析度或持續時間。
- **保持升級路徑的確定性**：在草稿和最終版本之間保留種子、提示和關鍵參數。
- **為快速循環而設計**：草稿模式旨在壓縮迭代時間。「升級」、「複製到最終版」和「比較」等操作應一鍵可及。
- **防止意外降級**：切勿將繁重任務靜默路由到草稿品質。若為效能自動切換，需提供明確通知和一鍵覆寫功能。
- **在提交點附近揭露成本控制**：在使用者選擇草稿或最終版的地方，直接標示 token、時間或點數的影響。

### 相關模式（Related Patterns）

- **`Sample response`**：當需要在投入產出前確認格式時使用，它提供一小部分全品質的切片，與草稿模式的低逼真度預覽不同。
- **`Model management`**：當目標是更廣泛地控制哪個模型執行任務時使用。
- **`Parameters`**：當使用者需要直接調整速度、品質或步驟時，揭露參數。

### 案例示例（Pattern Examples）

- **`Adobe Firefly`**：允許使用者用自己的聲音為音效設計草稿。
- **`Chronicle`**：在生成完整簡報前，先產生每張投影片的草稿大綱作為行動計畫供使用者確認。
- **`ElevenLabs`**：在生成完整語音簽名並存入庫前，先產生語音樣本供比較。
- **`Gamma`**：透過草稿大綱展示其計畫，供使用者在生成投影片前審查。
- **`Jasper`**：為長篇內容生成草稿大綱，供使用者在生成完整文件前審查。
- **`Krea.ai`**：支援即時草稿，這是 AI 圖像產生器中的常見模式。
- **`Leonardo.ai`**：的即時畫布允許使用者勾勒出他們預期圖像的草圖，並即時看到它根據提示渲染的效果。
- **`Midjourney`**：草稿模式保留了完整產生器的功能，但使用較低階的模型以降低快速迭代的算力成本。
- **`Replit`**：提供建立生成視覺預覽的選項，供使用者在投入完整應用程式建構前審查。
- **`Runway`**：明確建議在升級到最強大的模型前，先用較弱的模型起草影片。
- **`Synthesia`**：從編輯畫布產生草稿影片預覽，供使用者在匯出前審查。
- **`Udio`**：預設為 30 秒的片段，使用者可以預先更改此長度，或在準備好後延長草稿片段。

## Memory

### 頁面整體介紹

「Memory（記憶）」賦予 AI 系統在多次互動中保留和重複使用資訊的能力，為使用者創造連續性。系統可以回憶先前的上下文、偏好或事實，並將其應用於新任務，從而將 AI 從交易型工具轉變為持久的助理。設計良好的記憶可以減少摩擦，但也帶來風險，例如記憶錯誤或累積不相關的細節。因此，記憶必須是可見且可控的。

### 關鍵維度

- **`Knowledge map`（知識圖譜）**：展示 AI 記住了什麼以及它如何影響輸出。
- **`Scoped memory`（範圍記憶）**：資訊只在專案、工作區或對話中保留，防止無關資訊的滲透。
- **`Editable details`（可編輯細節）**：使用者應能夠策劃 AI 捕捉到的資訊，包括編輯、刪除或新增細節。
- **`Clear the cache`（清除快取）**：提供「重置記憶」的選項，一步清除所有記住的資料。

### 變體與形式

- **`Global memory`（全域記憶）**：資訊適用於所有介面和上下文，適用於持久性偏好。
- **`Scoped memory`（範圍記憶）**：資訊在特定範圍內保留，防止不相關的資訊轉移。
- **`Ephemeral memory`（短暫記憶）**：僅在當前會話中保留上下文，類似於無痕模式。

### 設計建議

- **記憶不應是黑盒子**：當新增記憶時，應通知使用者，並使其易於管理和控制。
- **區分偏好與記憶**：使用者的身份和溝通方式是不同的，應建立一個能夠對應人類細微差別的系統。
- **允許程式碼切換**：在不同情境下，可能需要不同的記憶集合或對應。
- **標記捕捉的時刻**：每當 AI 儲存某些內容時，提供一個輕量級的提示，邀請快速審查。
- **支援臨時和遺忘模式**：提供清晰的「關閉記憶」或「無痕」選項。

### 相關模式（Related Patterns）

- **`Voice and tone`**：將個人聲音與整體或專案記憶結合，定義一致的上下文。
- **`Incognito Mode`**：提供無痕模式，在執行敏感任務時完全禁用記憶。

### 案例示例（Pattern Examples）

- **`ChatGPT`**：允許使用者管理一個永久記憶供 AI 參考，並能從過去的聊天中推斷出偽記憶。
- **`Claude`**：不支援完整記憶，但能透過回顧過去的聊天來理解使用者。
- **`Gemini`**：儲存使用者要求記住的記憶，並隨時供使用者管理。
- **`Kin`**：將使用者的所有記憶儲存在圖表中，供使用者互動和管理。
- **`Perplexity`**：不支援完整記憶，但若使用者提供介紹，則會儲存相關資訊。
- **`Personal.ai`**：可以分享使用者的詳細資訊，形成一種記憶地圖。

## References

### 頁面整體介紹

「References（參考資料）」是 AI 系統用來塑造其輸出的外部材料。它們在模型的靜態訓練資料和使用者的即時上下文之間架起橋樑，將回應建立在可見且可驗證的資訊基礎上。此模式高度依賴檢索增強生成（RAG），將基礎知識與外部資料結合。

### 常見變體

- **`Panel`（面板）**：參考資料可能被分組在一個面板中，通常放置在內容右側以便掃描。
- **`Hidden aside`（隱藏側欄）**：參考來源可能被分組在一個標籤頁或抽屜中，易於查閱但降低了其在介面中的顯著性。
- **`Nested`（巢狀）**：在對話等較小介面中，參考資料通常被截斷以適應容器限制，並巢狀地分組在內容區塊的頂部或底部。

### 設計建議

- **讓參考資料易於定位**：無論是在行內、面板中還是標籤頁中，都應一致地放置它們。
- **參考資料的顯著性應與使用情境相符**：若使用者意圖是搜尋資源列表，則應突顯參考資料；若重點在於主要答案，則可降低其顯著性。
- **僅顯示足夠的細節**：平衡參考資料的複雜性和元資料與使用者的熟悉度和需求。
- **讓使用者控制參考資料**：允許使用者在初次生成後移除某些參考資料、重新界定範圍或自行新增附件。
- **直接處理遺失的來源**：應明確標示失效的連結或無法取得的資料，不要用填充內容替代。

### 相關模式（Related Patterns）

- **`Attachments`**：在編譯參考資料時，將附件視為第一級來源。
- **`Citations`**：生成的摘要與引文可以幫助使用者視覺化哪些參考資料適用於查詢的不同方面。

### 案例示例（Pattern Examples）

- **`Microsoft Bing`**：在其提供的摘要下方以巢狀方式列出參考資料。
- **`ChatGPT`**：在「深度研究」模式下，將所有來源放在一個易於存取但不用時可隱藏的側邊面板中。
- **`Copy.ai`**：將來源巢狀地列在摘要下方。
- **`Dia browser`**：將參考資料分組在一個可從結果上方連結存取的隱藏面板中。
- **`Fin`**：在聊天中將參考資料巢狀地置於其提供的引文下方。
- **`Glean`**：在聊天中以巢狀方式呈現參考來源。
- **`Google`**：採用面板變體，在搜尋摘要旁顯著地顯示頂級結果。
- **`Metaview`**：在聊天限制內包含參考資料，因此在內容下方以巢狀方式呈現時，會最小化元資料。
- **`Notion`**：將其完整的參考資料列表隱藏在帶有引文的摘要上方的抽屜中。
- **`Perplexity`**：將參考資料分組在內容上方的標籤頁中，並依賴行內引文將其摘要與參考來源連結。
- **`Sana`**：將其結果收集在主內容右側的側邊欄中。

## Sample response

### 頁面整體介紹

「Sample responses（樣本回應）」是在投入完整的、耗時的結果之前生成的輕量級輸出。它們讓使用者快速預覽 AI 打算做什麼，讓他們在消耗資源或覆蓋內容之前確認方向。這種模式將控制權交還給使用者，減少了因格式或意圖不匹配而產生的挫敗感，並為 AI 公司節省了算力。

### 設計建議

- **展示最終意圖和精緻度**：樣本應展示 AI 能多有效地渲染資料或透過提示匹配使用者的意圖。
- **讓使用者可以選擇跳過**：對於後續的迭代，這個額外的步驟可能變得不必要或麻煩，應允許使用者選擇直接執行。
- **在擴大規模前顯示成本和時間**：在樣本旁邊提供每個記錄的操作成本估算。
- **在高風險或影響範圍大時預設使用樣本**：如果自動填充操作可能導致巨大的計算成本或工作遺失，預設進行樣本測試是合適的。
- **在現有記錄旁邊顯示樣本**：避免覆寫現有內容，應在面板或覆蓋層中顯示樣本。

### 相關模式（Related Patterns）

- **`Auto fill`**：樣本回應通常與自動填充操作一起出現，允許使用者在對所有記錄執行操作或設定自動執行前驗證其提示。
- **`Draft mode`**：在測試單次執行的提示或參數時，應使用草稿模式，它會在放大最終版本前以較低品質產生逼真的輸出。

### 案例示例（Pattern Examples）

- **`Notion`**：在驗證樣本回應後，提供關於後續步驟的清晰細節，包括它將覆寫使用者資料的事實。其「在此視圖上試用」操作會主動鼓勵使用者在對整個資料庫執行提示前先進行測試和驗證。

## Shared vision

### 頁面整體介紹

「Shared vision（共享視窗）」提供使用者監控 AI 自主操作的介面，讓他們可以在不中斷其流程的情況下進行觀察，並在必要時進行干預。這種類似於數位世界中的「駕駛艙視圖」，透過細微的提示（如發光邊框、即時瀏覽器畫面）告知使用者 AI 正在「看」什麼和「做」什麼，從而建立人機之間的信任與協作感。

### 設計建議

- **確保增加的摩擦是合理的**：若使用者已習慣 AI 能自主完成任務，反覆要求介入會令人沮喪。應考慮在開始前，讓 AI 預先審查可能需要的權限並主動請求。
- **不要讓使用者將監督與完全安全混淆**：AI 易受提示注入等惡意攻擊。僅僅提醒使用者 AI 正在瀏覽器中活動可能不足以防範此類安全漏洞。
- **讓使用者限制控制範圍**：將共享視圖限制在特定標籤頁、應用程式或框架內，而非整個系統的存取權限。
- **持續以視覺方式標示邊界**：使用獨特的覆蓋層、彩色輪廓或工具提示來顯示 AI 可以看到或操作的內容。
- **為反向監督而設計**：在 AI 的思維流中包含螢幕截圖和具體細節，以便使用者審核 AI 所見之物及其行動。

### 相關模式（Related Patterns）

- **`Stream of Thought`**：在審核 AI 如何達成決策或行動時，使用者可依賴思維鏈來揭示模型如何使用工具和資源。
- **`Verification`**：即使 AI 在代理模式下自主運作，也可以在關鍵時刻（如可能分享敏感資料或產生費用時）建立驗證步驟，將人類納入迴圈。
- **`Controls`**：最簡單的例子是實作控制項，允許使用者即時停止、暫停和修改模型的生成。
- **`Footprints`**：使用足跡來附加人類在 AI 流程中介入的地點和方式的明顯證據，以便審查者區分 AI 和人類活動。

### 案例示例（Pattern Examples）

- **`ChatGPT Operator Mode`**：無縫地存在於對話介面中。使用者可以觀察 AI 在多個瀏覽器視窗間導航，執行動作，直到任務完成或需要使用者介入的步驟。

## Stream of Thought

### 頁面整體介紹

「Stream of Thought（思維流）」揭示了 AI 從輸入到答案的導航過程的可見痕跡。這可能包括它形成的計畫、呼叫的工具、代表使用者執行的程式碼，以及它所做的檢查和決策。當這些資訊可見時，系統變得更易讀，也更容易信任。此模式的實際形式簡單且幾乎通用：一個有邊界的方塊，細節被最小化或完全隱藏在點擊之後，即時顯示 AI 的邏輯或在完成後供審查。

### 常見表現形式

- **`Human-readable plans`（人類可讀的計畫）**：預覽 AI 將要做什麼。
- **`Execution logs`（執行日誌）**：記錄工具呼叫、程式碼和結果。
- **`Compact summaries`（緊湊摘要）**：捕捉其邏輯推理、洞察和決策。

### 設計建議

- **行動前展示計畫**：呈現一個簡短、可編輯的步驟序列，包含成本、範圍和所需權限。
- **分離計畫、執行和證據**：保持三個視圖同步：將要發生什麼、發生了什麼，以及支援結果的是什麼。
- **根據上下文調整可見性**：根據模式、可用的 token 密度和使用者偏好設定預設值，然後提供漸進式揭露。
- **將步驟轉化為狀態**：將每個步驟視為一個清晰的狀態：排隊中、執行中、等待批准、錯誤、重試、已完成。
- **為學習而檢測**：記錄使用者介入的地方、哪些步驟被重試，以及哪些工具產生最多錯誤。
- **尊重模態規則**：在文字中，將輸出連結回創建它的步驟；在程式碼中，保持分析可讀和可匯出；在語音中，用一句話總結當前動作和下一個檢查點。
- **圍繞清晰的里程碑**：一個好的實作會預先展示一個緊湊的計畫，揭示範圍和成本，在執行時串流有意義的進度，並在結束時提供可分享的報告。

### 相關模式（Related Patterns）

- **`Citations`**：推理步驟解釋「過程」，而引文解釋「證據」。
- **`Controls`**：允許使用者在處理過程中查看思維鏈，並使用控制項在出錯時停止、暫停或修改動作。
- **`Action plan`**：在執行前顯示 AI 的預期路徑時使用。

### 案例示例（Pattern Examples）

- **`Accio`**：透明地展示其從搜尋到分析再到生成結果的完整過程。
- **`Bolt`**：在聊天面板中透明地展示其生成過程。
- **`ChatGPT`**：在思考任務中揭示其思維過程，即時顯示其邏輯推理及參考資料。
- **`Claude`**：在對話本身中顯示其思維鏈，而不是將其巢狀地放在一個可摺疊的面板中。
- **`Grok`**：將其檢索的來源分離到自己的卡片中，以使其與其邏輯分開。
- **`Julius`**：在其行動鏈的流程中生成產出物。
- **`Lovable`**：使用者可以跟隨 Lovable 的行動和推理，看它如何創建他們的專案。
- **`Perplexity`**：在其主應用程式和瀏覽器 Comet 的結果窗格上方的標籤頁中顯示其步驟。
- **`v0`**：遵循類似的路徑，行內揭示其邏輯，直到準備好開始建構。

## Variations

### 頁面整體介紹

「Variations（多樣化）」允許使用者比較模型對其提示的不同排列組合的回應。由於生成式 AI 本質上是機率性的，其結果總會有一定程度的隨機性。此模式讓使用者能對模型的邏輯進行一定程度的控制，無論是發散性地探索提示空間，還是收斂於最終結果。

### 常見呈現方式

- **`Branched variations`（分支變體）**：常見於視覺生成器，一次創建多個選項（通常為四個），源自同一種子，並以縮圖網格顯示。使用者可以對其中任何一個變體執行額外的提示和操作。
- **`Convergent variations`（收斂變體）**：在線性工作流程中，使用者從選項列表中選擇，選定的變體將被合併到主要內容中。
- **`Preset variations`（預設變體）**：一些文字編輯器會顯示套用不同操作的文字變體，例如展示更專業與更休閒的版本，或更簡潔與更詳細的版本。

### 設計建議

- **讓後續操作近在咫尺**：讓使用者能從變體本身選擇、合併或分支，以保持工作流程的順暢。
- **允許額外生成**：如果第一版或第一組變體不符合使用者需求，允許他們在同一介面重新生成新的變體。
- **使用參數讓使用者保持控制**：讓使用者更改變體的差異程度、是否使用一致的種子、包含多少變體等。
- **避免無意的替換**：未經確認，切勿覆寫原始輸出。變體應擴展工作區，而不是冒資料遺失或撤銷努力的風險。

### 相關模式（Related Patterns）

- **`Parameters`**：考慮允許使用者更改他們想要的變體數量，作為初始提示的一個參數。
- **`Branches`**：分支可用於強制產生不同的變體，並允許使用者對每個變體進行迭代，以探索不同的創意路徑。
- **`Regenerate`**：重新生成與變體不同，它允許更改底層的提示和參數，而變體則源自相同的種子。

### 案例示例（Pattern Examples）

- **`Adobe Firefly`**：在網格中顯示變體的縮圖，懸停時會出現選項下拉選單，可對任意或所有變體進行迭代。
- **`Copy.ai`**：使用者可以審查不同的變體，並選擇或修改最符合其需求的版本。
- **`FloraFauna`**：直接在畫布上生成圖像的變體，這些變體以節點形式創建，無需額外步驟即可在其上添加新分支。
- **`GitHub Copilot`**：不一定總是提供變體。它們可以被強制生成，或者在模型的情境信賴度較低時，模型可能會選擇生成多個選項。
- **`Grammarly`**：與 Writer 類似，使用預設變體，一次對同一文本提供多種操作。
- **`Ideogram`**：在生成器底部的滾動條中，將所有生成的所有變體一起顯示。
- **`Writer`**：提供預設變體，而不是多次生成相同的種子。

## Verification

### 頁面整體介紹

「Verification（驗證）」是在 AI 自主代表使用者採取行動時，要求人類協作者進行確認的機制。隨著 AI 在工作流程、操作員模式和代理中變得日益獨立，錯誤的決策可能導致資料遺失、意外成本或個人資訊洩露等負面後果。在 AI 代表使用者採取行動的任何情況下，都可能需要先獲得人類的驗證。

### 何時需要驗證

- 對於風險低的簡單任務，不需要驗證。
- 當錯誤的行動會產生實際影響時（如聲譽損失、金錢損失、安全損失、工作損失、時間損失），應預設要求驗證。

### 驗證類型

- **`Simple verification`（簡單驗證）**：基本的「同意-不同意」決策模式，常見於 AI 的行動計畫或樣本回應。
- **`Proactive platform rules`（主動平台規則）**：平台設定明確的限制，要求在特定情況下（如涉及支付資料）進行使用者介入。
- **`User overrides`（使用者覆寫）**：允許使用者透過設定或指示，自訂何時需要停止或進行驗證。

### 設計建議

- **摩擦力應與風險相匹配**：根據行動的潛在危害、範圍和可逆性來觸發驗證。
- **使用選擇退出設定以實現完全控制**：提供「不再顯示」的選項，讓使用者完全掌控其體驗。
- **明確標示是否跳過驗證**：當驗證被跳過時，提供清晰的提示，並允許使用者隨時重新啟用。
- **在需要使用者操作時發出警報**：透過第三方工具連接或其他觸發器，提醒使用者需要介入。

### 相關模式（Related Patterns）

- **`Cost estimates`**：不僅要驗證行動本身，還要確保使用者了解昂貴操作將產生的成本。
- **`Sample response`**：使用驗證步驟來確認樣本回應是否符合使用者的意圖，然後再執行工作流程或自動填充操作。

### 案例示例（Pattern Examples）

- **`Atlassian Intelligence`**：在 Jira 問題單中展示行內驗證。
- **`Chronicle`**：在創建簡報前生成大綱，使用者必須驗證大綱是否符合要求，AI 才會繼續。
- **`Cofounder`**：預設情況下，代理在代表使用者採取行動前總是要求驗證。
- **`Cursor`**：對於檔案的行內更改，需要驗證，之後程式碼才會被插入檔案中。
- **`Dovetail`**：建議重點和相關見解，但在將其添加到綜合研究報告之前，需要使用者驗證。
- **`Notion`**：在將文字變更添加到文件之前，需要使用者驗證。
- **`Replit`**：在進行耗時且消耗大量算力的建構過程之前，讓使用者驗證其行動計畫。

***

## 深入案例研究：Claude 與 Perplexity 的人機協作功能與暗黑模式風險分析

以 Claude 和 Perplexity 為主要研究對象，檢視當前主流 AI 系統如何實作人機協作功能，並分析這些功能潛在的暗黑模式風險與使用者自主權維護機制。

### 1. 透明度機制與其風險

- **Stream of Thought（思維流）與透明度建立**：
  - **Claude 實作**：在對話中直接顯示其思維鏈，讓使用者能即時監控推理過程、建立信任，並提供介入時機。
  - **Perplexity 實作**：在結果窗格上方標籤頁中顯示其步驟，包括搜尋策略、資訊篩選過程與綜合邏輯，展示其研究流程。
  - **潛在暗黑模式風險**：虛假透明度（表面揭露但隱藏關鍵邏輯）、認知負擔轉移（將驗證責任過度轉移給使用者）。

- **Citations（引文）與可驗證性**：
  - **Perplexity 實作**：將引文視為核心功能，同時引用多個來源以支持單一論點，並讓使用者可直接點擊查看原始來源。
  - **潛在暗黑模式風險**：來源選擇偏見（可能偏好特定來源）、引文品質不佳（引用失效或不可靠來源）。

### 2. 控制與上下文管理機制與其風險

- **Memory（記憶）與上下文管理**：
  - **Claude 實作**：雖不支援完整記憶，但能透過回顧過去聊天來理解使用者，並從歷史互動中推斷偏好。
  - **潛在暗黑模式風險**：隱性資料收集（未明確告知下累積使用者資訊）、脈絡操控（選擇性提取歷史資訊影響對話）。

- **Controls（控制項）與 Action Plan（行動計畫）**：
  - **Claude 實作**：提供生成中斷、重新生成等即時控制機制。其行動計畫直接在對話中展示。
  - **Perplexity 實作**：允許在研究過程中引入新上下文調整方向。其行動計畫則是在研究模式下分步驟展示。
  - **潛在暗黑模式風險**：誘導使用者接受不當計畫、執行過程可能偏移產生期望落差。

### 3. 成本與驗證機制的風險

- **Verification（驗證）機制**：
  - **Claude 特色**：在生成過程中提供多次確認點（生成驗證），並允許使用者在內容修改前進行確認（內容驗證）。
  - **Perplexity 特色**：強調原始資料的可追溯性（來源驗證），並透過多重引文支持結果可信度（結果驗證）。

- **Cost Estimates（成本估算）與透明度**：
  - **平台差異**：Claude 對一般使用者隱藏具體成本細節；Perplexity 的免費與付費層權限區分明確。
  - **潛在暗黑模式風險**：隱藏成本結構、在接近用量限制時採用 Nagging 模式推動付費升級。

### 辨識要點：人機協作功能的暗黑模式識別框架

#### 透明度檢查清單
1.  **思維過程揭露**：AI 是否真實展示決策邏輯，而非表演性透明？
2.  **資料來源標示**：所有引文和參考資料是否準確且可驗證？
3.  **成本資訊完整性**：使用者是否充分了解操作的真實成本？
4.  **記憶功能邊界**：資料收集和使用範圍是否明確告知？

#### 控制權保障機制
1.  **即時中斷能力**：使用者是否隨時可以停止或修改 AI 行為？
2.  **設定可調整性**：協作功能是否允許個人化設定？
3.  **資料主權**：使用者是否擁有自己資料的完整控制權？
4.  **退出機制**：是否提供徹底退出特定功能的選項？

#### 認知負擔評估
1.  **預設選項合理性**：系統預設是否符合使用者最佳利益？
2.  **選擇複雜度**：選項設計是否避免選擇疲勞和混淆？
3.  **錯誤修正容易度**：使用者能否輕易撤銷或修正錯誤決策？
4.  **學習曲線管理**：新功能引入是否循序漸進？

### 建議改進方向

#### 增強使用者自主權
- **細粒度控制**：提供更精細的功能開關和個人化設定。
- **透明度儀表板**：建立專門介面展示所有 AI 活動和資源使用情況。
- **批量操作確認**：對可能產生重大影響的操作要求明確確認。

#### 防範暗黑模式設計
- **獨立審計機制**：引入第三方審計評估協作功能的倫理性。
- **使用者反饋循環**：建立常態化的使用者體驗回饋機制。
- **設計倫理準則**：制定明確的人機協作設計倫理標準。

#### 提升協作體驗品質
- **情境感知優化**：根據不同使用情境調整協作介面和功能。
- **錯誤恢復改善**：加強錯誤處理和恢復機制的使用者友善性。
- **跨平台一致性**：確保不同裝置和介面間的協作體驗一致性。


